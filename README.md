# llm-color-tester
LLMs are capable of spectacular feats, and they are also capable of spectacularly random flame-outs. A big systems engineering issue remains figuring out how to tell one from the other. Here is an example for the latter.

It is well-known that LLM performance is very sensitive to prompt formulation. In some cases, that makes “algorithmic sense”, like when prompting an LLM to operate in chain-of-thought (“think through this step by step”): that effectively makes the LLM use its own output as short-term memory, which means you’re effectively chaining many LLMs together. In other cases, it doesn’t make any algorithmic sense, but human intuition helps realize why a particular prompt works: for example, prompting the LLM to “take a deep breath” apparently increases performance by a little, perhaps because there is enough pattern matching in the pre-training data that this is associated with better performance, so it biases the LLM output towards that better performance. But in other cases, prompt complexity is just weird and hard to quantitatively assess upfront. Here is a really simple example.

We came across this when asking the LLM to a) categorize many comments from members by topical area and b) show which comment belongs to which categories, in one go. That seemingly simple prompt fails in hard to predict ways. So we tried to create a cleaner experiment. The experiment is as follows: we created a list of 280 objects that have a definitive color, which should be clear and obvious in the LLM’s pre-training data. For example, an arctic hare is white, a domino is black, a cauliflower is white, a radish is red, spinach is green, grass is green etc.

This code tests GPT-4 by giving it a list of objects and asking it to categorize each object by color. The simplest prompt (noranking) does just that. The more complex prompt also asks it to then group the objects by common color, and rank the object groups by frequency of color occurrence. It is that more complex prompt that seems to "break" GPT-4 at times.
